
//
// This file was generated by llmaker.
//

use std::iter::Peekable;
use super::lexer;
use super::types;



#[derive(Debug, Clone)]
pub enum ParseError {
  UnexpectedToken(lexer::Token),
  RedundantExpression(lexer::Token),
  Eof,
}


#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
pub fn parse(tokens: Vec<lexer::Token>) -> Result<types::UntypedAST, ParseError> {
  let mut tokens = tokens.into_iter().peekable();
  let ret = _parse_fn_main(&mut tokens)?;
  match tokens.next() {
    Some(tok) => Err(ParseError::RedundantExpression(tok)),
    None => Ok(ret),
  }
}


#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_main<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<types::UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::FALSE            , _) | (lexer::TokenKind::FLOATCONST    (_), _) | (lexer::TokenKind::IF               , _) | (lexer::TokenKind::INTCONST      (_), _) | (lexer::TokenKind::LPAREN           , _) | (lexer::TokenKind::TRUE             , _) | (lexer::TokenKind::VAR           (_), _) => { Ok(CodeType::Tok1) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let utast = _parse_fn_xif(tokens)?;
let _ = _parse_token_Tok_EOF(tokens)?;
utast }
    _ => { return Err(ParseError::UnexpectedToken(tokens.next().unwrap())) }
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_xif<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<types::UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,Tok2,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::IF               , _) => { Ok(CodeType::Tok1) }
(lexer::TokenKind::FALSE            , _) | (lexer::TokenKind::FLOATCONST    (_), _) | (lexer::TokenKind::INTCONST      (_), _) | (lexer::TokenKind::LPAREN           , _) | (lexer::TokenKind::TRUE             , _) | (lexer::TokenKind::VAR           (_), _) => { Ok(CodeType::Tok2) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let opn = _parse_token_Tok_IF(tokens)?;
let utast1 = _parse_fn_lor(tokens)?;
let _ = _parse_token_Tok_THEN(tokens)?;
let utast2 = _parse_fn_lor(tokens)?;
let _ = _parse_token_Tok_ELSE(tokens)?;
let utast3 = _parse_fn_lor(tokens)?;

    let (_,rngs) = opn;
    let (_,rnge) = utast3;
    let rng = rngs.merge(&rnge);
    (
      types::UntypedASTMain::IfThenElse(
        Box::new(utast1),
        Box::new(utast2),
        Box::new(utast3)
      ),
      rng
    ) }CodeType::Tok2 => { let utast = _parse_fn_lor(tokens)?;
utast }
    _ => { return Err(ParseError::UnexpectedToken(tokens.next().unwrap())) }
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_lor<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<types::UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::FALSE            , _) | (lexer::TokenKind::FLOATCONST    (_), _) | (lexer::TokenKind::INTCONST      (_), _) | (lexer::TokenKind::LPAREN           , _) | (lexer::TokenKind::TRUE             , _) | (lexer::TokenKind::VAR           (_), _) => { Ok(CodeType::Tok1) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let utast = _parse_fn_land(tokens)?;
let utaststr2opt = _parse_fn_lor_sub(tokens)?;

    match utaststr2opt {
      None => {utast}
      Some((op, utastr)) => {
        let (tok, rng) = op;
        let st = lexer::get_string(tok).unwrap();
        types::binary_operator(utast, (st, rng), utastr)
      }
    } }
    _ => { return Err(ParseError::UnexpectedToken(tokens.next().unwrap())) }
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_lor_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Option<(lexer::Token, types::UntypedAST)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::BINOP_BAR     (_), _) => { Ok(CodeType::Tok1) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let op = _parse_token_Tok_BINOP_BAR(tokens)?;
let utastr = _parse_fn_land(tokens)?;
let subopt = _parse_fn_lor_sub(tokens)?;

    match subopt {
      None => {Some((op, utastr))}
      Some((op2, utastr2)) => {
        let (tok, rng) = op2;
        let st = lexer::get_string(tok).unwrap();
        Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
      }
    } }
    _ => { None }
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_land<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<types::UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::FALSE            , _) | (lexer::TokenKind::FLOATCONST    (_), _) | (lexer::TokenKind::INTCONST      (_), _) | (lexer::TokenKind::LPAREN           , _) | (lexer::TokenKind::TRUE             , _) | (lexer::TokenKind::VAR           (_), _) => { Ok(CodeType::Tok1) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let utast = _parse_fn_leq_lt_gt(tokens)?;
let utaststr2opt = _parse_fn_land_sub(tokens)?;

    match utaststr2opt {
      None => {utast}
      Some((op, utastr)) => {
        let (tok, rng) = op;
        let st = lexer::get_string(tok).unwrap();
        types::binary_operator(utast, (st, rng), utastr)
      }
    } }
    _ => { return Err(ParseError::UnexpectedToken(tokens.next().unwrap())) }
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_land_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Option<(lexer::Token, types::UntypedAST)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::BINOP_AMP     (_), _) => { Ok(CodeType::Tok1) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let op = _parse_token_Tok_BINOP_AMP(tokens)?;
let utastr = _parse_fn_leq_lt_gt(tokens)?;
let subopt = _parse_fn_land_sub(tokens)?;

    match subopt {
      None => {Some((op, utastr))}
      Some((op2, utastr2)) => {
        let (tok, rng) = op2;
        let st = lexer::get_string(tok).unwrap();
        Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
      }
    } }
    _ => { None }
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_leq_lt_gt<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<types::UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::FALSE            , _) | (lexer::TokenKind::FLOATCONST    (_), _) | (lexer::TokenKind::INTCONST      (_), _) | (lexer::TokenKind::LPAREN           , _) | (lexer::TokenKind::TRUE             , _) | (lexer::TokenKind::VAR           (_), _) => { Ok(CodeType::Tok1) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let utast = _parse_fn_lhat(tokens)?;
let utaststr2opt = _parse_fn_leq_lt_gt_sub(tokens)?;

    match utaststr2opt {
      None => {utast}
      Some((op, utastr)) => {
        let (tok, rng) = op;
        let st = lexer::get_string(tok).unwrap();
        types::binary_operator(utast, (st, rng), utastr)
      }
    } }
    _ => { return Err(ParseError::UnexpectedToken(tokens.next().unwrap())) }
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_leq_lt_gt_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Option<(lexer::Token, types::UntypedAST)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,Tok2,Tok3,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::BINOP_EQ      (_), _) => { Ok(CodeType::Tok1) }
(lexer::TokenKind::BINOP_LT      (_), _) => { Ok(CodeType::Tok2) }
(lexer::TokenKind::BINOP_GT      (_), _) => { Ok(CodeType::Tok3) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let op = _parse_token_Tok_BINOP_EQ(tokens)?;
let utastr = _parse_fn_lhat(tokens)?;
let subopt = _parse_fn_leq_lt_gt_sub(tokens)?;

    match subopt {
      None => {Some((op, utastr))}
      Some((op2, utastr2)) => {
        let (tok, rng) = op2;
        let st = lexer::get_string(tok).unwrap();
        Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
      }
    } }CodeType::Tok2 => { let op = _parse_token_Tok_BINOP_LT(tokens)?;
let utastr = _parse_fn_lhat(tokens)?;
let subopt = _parse_fn_leq_lt_gt_sub(tokens)?;

    match subopt {
      None => {Some((op, utastr))}
      Some((op2, utastr2)) => {
        let (tok, rng) = op2;
        let st = lexer::get_string(tok).unwrap();
        Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
      }
    } }CodeType::Tok3 => { let op = _parse_token_Tok_BINOP_GT(tokens)?;
let utastr = _parse_fn_lhat(tokens)?;
let subopt = _parse_fn_leq_lt_gt_sub(tokens)?;

    match subopt {
      None => {Some((op, utastr))}
      Some((op2, utastr2)) => {
        let (tok, rng) = op2;
        let st = lexer::get_string(tok).unwrap();
        Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
      }
    } }
    _ => { None }
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_lhat<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<types::UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::FALSE            , _) | (lexer::TokenKind::FLOATCONST    (_), _) | (lexer::TokenKind::INTCONST      (_), _) | (lexer::TokenKind::LPAREN           , _) | (lexer::TokenKind::TRUE             , _) | (lexer::TokenKind::VAR           (_), _) => { Ok(CodeType::Tok1) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let utast = _parse_fn_lpl_mi(tokens)?;
let utaststr2opt = _parse_fn_lhat_sub(tokens)?;

    match utaststr2opt {
      None => {utast}
      Some((op, utastr)) => {
        let (tok, rng) = op;
        let st = lexer::get_string(tok).unwrap();
        types::binary_operator(utast, (st, rng), utastr)
      }
    } }
    _ => { return Err(ParseError::UnexpectedToken(tokens.next().unwrap())) }
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_lhat_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Option<(lexer::Token, types::UntypedAST)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::BINOP_HAT     (_), _) => { Ok(CodeType::Tok1) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let op = _parse_token_Tok_BINOP_HAT(tokens)?;
let utastr = _parse_fn_lpl_mi(tokens)?;
let subopt = _parse_fn_lhat_sub(tokens)?;

    match subopt {
      None => {Some((op, utastr))}
      Some((op2, utastr2)) => {
        let (tok, rng) = op2;
        let st = lexer::get_string(tok).unwrap();
        Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
      }
    } }
    _ => { None }
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_lpl_mi<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<types::UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::FALSE            , _) | (lexer::TokenKind::FLOATCONST    (_), _) | (lexer::TokenKind::INTCONST      (_), _) | (lexer::TokenKind::LPAREN           , _) | (lexer::TokenKind::TRUE             , _) | (lexer::TokenKind::VAR           (_), _) => { Ok(CodeType::Tok1) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let utast = _parse_fn_lti_div(tokens)?;
let utaststr2opt = _parse_fn_lpl_mi_sub(tokens)?;

    match utaststr2opt {
      None => {utast}
      Some((op, utastr)) => {
        let (tok, rng) = op;
        let st = lexer::get_string(tok).unwrap();
        types::binary_operator(utast, (st, rng), utastr)
      }
    } }
    _ => { return Err(ParseError::UnexpectedToken(tokens.next().unwrap())) }
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_lpl_mi_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Option<(lexer::Token, types::UntypedAST)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,Tok2,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::BINOP_PLUS    (_), _) => { Ok(CodeType::Tok1) }
(lexer::TokenKind::BINOP_MINUS   (_), _) => { Ok(CodeType::Tok2) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let op = _parse_token_Tok_BINOP_PLUS(tokens)?;
let utastr = _parse_fn_lti_div(tokens)?;
let subopt = _parse_fn_lpl_mi_sub(tokens)?;

    match subopt {
      None => {Some((op, utastr))}
      Some((op2, utastr2)) => {
        let (tok, rng) = op2;
        let st = lexer::get_string(tok).unwrap();
        Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
      }
    } }CodeType::Tok2 => { let op = _parse_token_Tok_BINOP_MINUS(tokens)?;
let utastr = _parse_fn_lti_div(tokens)?;
let subopt = _parse_fn_lpl_mi_sub(tokens)?;

    match subopt {
      None => {Some((op, utastr))}
      Some((op2, utastr2)) => {
        let (tok, rng) = op2;
        let st = lexer::get_string(tok).unwrap();
        Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
      }
    } }
    _ => { None }
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_lti_div<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<types::UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::FALSE            , _) | (lexer::TokenKind::FLOATCONST    (_), _) | (lexer::TokenKind::INTCONST      (_), _) | (lexer::TokenKind::LPAREN           , _) | (lexer::TokenKind::TRUE             , _) | (lexer::TokenKind::VAR           (_), _) => { Ok(CodeType::Tok1) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let utast = _parse_fn_bot(tokens)?;
let utaststr2opt = _parse_fn_lti_div_sub(tokens)?;

    match utaststr2opt {
      None => {utast}
      Some((op, utastr)) => {
        let (tok, rng) = op;
        let st = lexer::get_string(tok).unwrap();
        types::binary_operator(utast, (st, rng), utastr)
      }
    } }
    _ => { return Err(ParseError::UnexpectedToken(tokens.next().unwrap())) }
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_lti_div_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Option<(lexer::Token, types::UntypedAST)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,Tok2,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::BINOP_TIMES   (_), _) => { Ok(CodeType::Tok1) }
(lexer::TokenKind::BINOP_DIVIDES (_), _) => { Ok(CodeType::Tok2) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let op = _parse_token_Tok_BINOP_TIMES(tokens)?;
let utastr = _parse_fn_bot(tokens)?;
let subopt = _parse_fn_lti_div_sub(tokens)?;

    match subopt {
      None => {Some((op, utastr))}
      Some((op2, utastr2)) => {
        let (tok, rng) = op2;
        let st = lexer::get_string(tok).unwrap();
        Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
      }
    } }CodeType::Tok2 => { let op = _parse_token_Tok_BINOP_DIVIDES(tokens)?;
let utastr = _parse_fn_bot(tokens)?;
let subopt = _parse_fn_lti_div_sub(tokens)?;

    match subopt {
      None => {Some((op, utastr))}
      Some((op2, utastr2)) => {
        let (tok, rng) = op2;
        let st = lexer::get_string(tok).unwrap();
        Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
      }
    } }
    _ => { None }
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_bot<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<types::UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,Tok2,Tok3,Tok4,Tok5,Tok6,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::INTCONST      (_), _) => { Ok(CodeType::Tok1) }
(lexer::TokenKind::FLOATCONST    (_), _) => { Ok(CodeType::Tok2) }
(lexer::TokenKind::TRUE             , _) => { Ok(CodeType::Tok3) }
(lexer::TokenKind::FALSE            , _) => { Ok(CodeType::Tok4) }
(lexer::TokenKind::LPAREN           , _) => { Ok(CodeType::Tok5) }
(lexer::TokenKind::VAR           (_), _) => { Ok(CodeType::Tok6) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let inttok = _parse_token_Tok_INTCONST(tokens)?;

    let (tok, rng) = inttok;
    let i = lexer::get_i64(tok).unwrap();
    (types::UntypedASTMain::IntConst(i), rng) }CodeType::Tok2 => { let floattok = _parse_token_Tok_FLOATCONST(tokens)?;

    let (tok, rng) = floattok;
    let f = lexer::get_f64(tok).unwrap();
    (types::UntypedASTMain::FloatConst(f), rng) }CodeType::Tok3 => { let truetok = _parse_token_Tok_TRUE(tokens)?;

    let (_, rng) = truetok;
    (types::UntypedASTMain::BoolConst(true), rng) }CodeType::Tok4 => { let falsetok = _parse_token_Tok_FALSE(tokens)?;

    let (_, rng) = falsetok;
    (types::UntypedASTMain::BoolConst(false), rng) }CodeType::Tok5 => { let opn = _parse_token_Tok_LPAREN(tokens)?;
let utast = _parse_fn_xif(tokens)?;
let cls = _parse_token_Tok_RPAREN(tokens)?;

    let (_, rngo) = opn;
    let (_, rngc) = cls;
    let (main,_) = utast;
    (main, rngo.merge(&rngc)) }CodeType::Tok6 => { let fname = _parse_token_Tok_VAR(tokens)?;
let _ = _parse_token_Tok_LPAREN(tokens)?;
let args = _parse_fn_args(tokens)?;
let cls = _parse_token_Tok_RPAREN(tokens)?;

    let (nametok,rngs) = fname;
    let name_str = lexer::get_string(nametok).unwrap();
    let (_,rnge) = cls;
    let rng = rngs.merge(&rnge);
    let mut args = args;
    args.reverse();
    (types::UntypedASTMain::Apply((name_str, rngs), args), rng) }
    _ => { return Err(ParseError::UnexpectedToken(tokens.next().unwrap())) }
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_args<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Vec<types::UntypedAST>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::FALSE            , _) | (lexer::TokenKind::FLOATCONST    (_), _) | (lexer::TokenKind::INTCONST      (_), _) | (lexer::TokenKind::LPAREN           , _) | (lexer::TokenKind::TRUE             , _) | (lexer::TokenKind::VAR           (_), _) => { Ok(CodeType::Tok1) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let arg = _parse_fn_lor(tokens)?;
let tail = _parse_fn_args_sub(tokens)?;

    let mut v = tail;
    v.push(arg);
    v }
    _ => { Vec::new() }
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_args_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Vec<types::UntypedAST>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other
  }
  let code_type =
  tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
  (lexer::TokenKind::COMMA            , _) => { Ok(CodeType::Tok1) }

    _ => {Ok(CodeType::Other)}
    });
  let main =
  match code_type? {
    CodeType::Tok1 => { let _ = _parse_token_Tok_COMMA(tokens)?;
let arg = _parse_fn_lor(tokens)?;
let tail = _parse_fn_args(tokens)?;

    let mut v = tail;
    v.push(arg);
    v }
    _ => { Vec::new() }
  };
  Ok(main)
}



#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_EOF<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::EOF              , _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_VAR<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::VAR           (_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_CONSTRUCTOR<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::CONSTRUCTOR   (_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_INTCONST<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::INTCONST      (_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_FLOATCONST<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::FLOATCONST    (_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_DEF_EQ<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::DEF_EQ           , _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_TIMES<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_TIMES   (_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_DIVIDES<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_DIVIDES (_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_PLUS<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_PLUS    (_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_MINUS<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_MINUS   (_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_HAT<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_HAT     (_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_AMP<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_AMP     (_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_BAR<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_BAR     (_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_GT<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_GT      (_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_LT<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_LT      (_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_EQ<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_EQ      (_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_LPAREN<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::LPAREN           , _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_RPAREN<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::RPAREN           , _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_SEMICOLON<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::SEMICOLON        , _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_COLON<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::COLON            , _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_COMMA<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::COMMA            , _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_TRUE<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::TRUE             , _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_FALSE<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::FALSE            , _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_IF<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::IF               , _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_THEN<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::THEN             , _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_ELSE<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::ELSE             , _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

