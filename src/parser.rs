//
// This file was generated by llmaker.
//

#![allow(dead_code)]
use std::cmp::Ordering;

use super::lexer;
use super::types;
use super::types::{Range, UntypedAST, UntypedASTMain};
use thiserror::Error;

#[derive(Debug, Clone, Error)]
pub enum ParseError {
  #[error("unexpected token: {0:?}")]
  UnexpectedToken(lexer::Token),
  #[error("redundant expression: {0:?}")]
  RedundantExpression(lexer::Token),
  #[error("EOF")]
  Eof,
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
pub fn parse(tokens: Vec<lexer::Token>) -> Result<UntypedAST, ParseError> {
  let (ret, pos) = _parse_fn_main(&tokens, 0)?;
  match pos.cmp(&tokens.len()) {
    Ordering::Equal => Ok(ret),
    Ordering::Greater => Err(ParseError::Eof), // pos > tokens.len()
    Ordering::Less => Err(ParseError::RedundantExpression(tokens[pos].clone())),
  }
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_main(tokens: &[lexer::Token], pos: usize) -> Result<(UntypedAST, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Code1,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::FALSE, _) => CodeType::Code0,
    (lexer::TokenKind::FLOATCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::IF, _) => CodeType::Code0,
    (lexer::TokenKind::INTCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::LAMBDA, _) => CodeType::Code0,
    (lexer::TokenKind::LETNONREC, _) => CodeType::Code1,
    (lexer::TokenKind::LETREC, _) => CodeType::Code1,
    (lexer::TokenKind::LPAREN, _) => CodeType::Code0,
    (lexer::TokenKind::TRUE, _) => CodeType::Code0,
    (lexer::TokenKind::VAR(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (utast, pos) = _parse_fn_nxif(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_EOF(tokens, pos)?;

      _token_pos = pos;
      utast
    }
    CodeType::Code1 => {
      let (utast, pos) = _parse_fn_nxtoplevel(tokens, pos)?;

      _token_pos = pos;
      utast
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_nxtoplevel(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(UntypedAST, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Code1,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::LETNONREC, _) => CodeType::Code0,
    (lexer::TokenKind::LETREC, _) => CodeType::Code1,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (opn, pos) = _parse_token_Tok_LETNONREC(tokens, pos)?;
      let (recdec, pos) = _parse_fn_nxnonrecdec(tokens, pos)?;
      let (subseq, pos) = _parse_fn_nxtopsubseq(tokens, pos)?;

      _token_pos = pos;
      let (name, utast) = recdec;
      let (_, opnrng) = opn;
      let (_, clsrng) = subseq;
      let rng = opnrng.merge(&clsrng);
      let main = UntypedASTMain::LetExp(name, Box::new(utast), Box::new(subseq));
      (main, rng)
    }
    CodeType::Code1 => {
      let (opn, pos) = _parse_token_Tok_LETREC(tokens, pos)?;
      let (recdec, pos) = _parse_fn_nxnonrecdec(tokens, pos)?;
      let (subseq, pos) = _parse_fn_nxtopsubseq(tokens, pos)?;

      _token_pos = pos;
      let (name, utast) = recdec;
      let (_, opnrng) = opn;
      let (_, clsrng) = subseq;
      let rng = opnrng.merge(&clsrng);
      let para = match utast.clone() {
        (types::UntypedASTMain::FunExp(para, _), _) => para,
        _ => panic!(),
      };
      let main = UntypedASTMain::LetRecExp(name, para, Box::new(utast), Box::new(subseq));
      (main, rng)
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_nxnonrecdec(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<((String, UntypedAST), usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Code1,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::LPAREN, _) => CodeType::Code1,
    (lexer::TokenKind::VAR(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (name, pos) = _parse_token_Tok_VAR(tokens, pos)?;
      let (vars, pos) = _parse_fn_varlist(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_DEF_EQ(tokens, pos)?;
      let (utast, pos) = _parse_fn_nxlet(tokens, pos)?;

      _token_pos = pos;
      let (name_token, _) = name;
      let name_string = lexer::get_string(name_token).unwrap();
      let (_, rng) = utast;
      let utast = if vars.is_empty() {
        utast
      } else {
        types::make_lambda_list(vars, utast, rng)
      };
      (name_string, utast)
    }
    CodeType::Code1 => {
      let (_, pos) = _parse_token_Tok_LPAREN(tokens, pos)?;
      let (name_string, pos) = _parse_fn_nxnonrecdec_sub_binop(tokens, pos)?;
      let (vars, pos) = _parse_fn_varlist(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_DEF_EQ(tokens, pos)?;
      let (utast, pos) = _parse_fn_nxlet(tokens, pos)?;

      _token_pos = pos;

      let (_, rng) = utast;
      let utast = if vars.is_empty() {
        utast
      } else {
        types::make_lambda_list(vars, utast, rng)
      };
      (name_string, utast)
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_nxnonrecdec_sub_binop(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(String, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Code1,
    Code2,
    Code3,
    Code4,
    Code5,
    Code6,
    Code7,
    Code8,
    Code9,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::BINOP_AMP(_), _) => CodeType::Code0,
    (lexer::TokenKind::BINOP_BAR(_), _) => CodeType::Code1,
    (lexer::TokenKind::BINOP_DIVIDES(_), _) => CodeType::Code2,
    (lexer::TokenKind::BINOP_EQ(_), _) => CodeType::Code3,
    (lexer::TokenKind::BINOP_GT(_), _) => CodeType::Code4,
    (lexer::TokenKind::BINOP_HAT(_), _) => CodeType::Code5,
    (lexer::TokenKind::BINOP_LT(_), _) => CodeType::Code6,
    (lexer::TokenKind::BINOP_MINUS(_), _) => CodeType::Code7,
    (lexer::TokenKind::BINOP_PLUS(_), _) => CodeType::Code8,
    (lexer::TokenKind::BINOP_TIMES(_), _) => CodeType::Code9,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (binop, pos) = _parse_token_Tok_BINOP_AMP(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (name_token, _) = binop;
      lexer::get_string(name_token).unwrap()
    }
    CodeType::Code1 => {
      let (binop, pos) = _parse_token_Tok_BINOP_BAR(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (name_token, _) = binop;
      lexer::get_string(name_token).unwrap()
    }
    CodeType::Code2 => {
      let (binop, pos) = _parse_token_Tok_BINOP_DIVIDES(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (name_token, _) = binop;
      lexer::get_string(name_token).unwrap()
    }
    CodeType::Code3 => {
      let (binop, pos) = _parse_token_Tok_BINOP_EQ(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (name_token, _) = binop;
      lexer::get_string(name_token).unwrap()
    }
    CodeType::Code4 => {
      let (binop, pos) = _parse_token_Tok_BINOP_GT(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (name_token, _) = binop;
      lexer::get_string(name_token).unwrap()
    }
    CodeType::Code5 => {
      let (binop, pos) = _parse_token_Tok_BINOP_HAT(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (name_token, _) = binop;
      lexer::get_string(name_token).unwrap()
    }
    CodeType::Code6 => {
      let (binop, pos) = _parse_token_Tok_BINOP_LT(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (name_token, _) = binop;
      lexer::get_string(name_token).unwrap()
    }
    CodeType::Code7 => {
      let (binop, pos) = _parse_token_Tok_BINOP_MINUS(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (name_token, _) = binop;
      lexer::get_string(name_token).unwrap()
    }
    CodeType::Code8 => {
      let (binop, pos) = _parse_token_Tok_BINOP_PLUS(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (name_token, _) = binop;
      lexer::get_string(name_token).unwrap()
    }
    CodeType::Code9 => {
      let (binop, pos) = _parse_token_Tok_BINOP_TIMES(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (name_token, _) = binop;
      lexer::get_string(name_token).unwrap()
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_nxtopsubseq(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(UntypedAST, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Code1,
    Code2,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::EOF, _) => CodeType::Code1,
    (lexer::TokenKind::IN, _) => CodeType::Code2,
    (lexer::TokenKind::LETNONREC, _) => CodeType::Code0,
    (lexer::TokenKind::LETREC, _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (utast, pos) = _parse_fn_nxtoplevel(tokens, pos)?;

      _token_pos = pos;
      utast
    }
    CodeType::Code1 => {
      let (eof, pos) = _parse_token_Tok_EOF(tokens, pos)?;

      _token_pos = pos;
      let (_, rng) = eof;
      (UntypedASTMain::FinishHeaderFile, rng)
    }
    CodeType::Code2 => {
      let (_, pos) = _parse_token_Tok_IN(tokens, pos)?;
      let (utast, pos) = _parse_fn_nxlet(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_EOF(tokens, pos)?;

      _token_pos = pos;
      utast
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_nxlet(tokens: &[lexer::Token], pos: usize) -> Result<(UntypedAST, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Code1,
    Code2,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::FALSE, _) => CodeType::Code2,
    (lexer::TokenKind::FLOATCONST(_), _) => CodeType::Code2,
    (lexer::TokenKind::IF, _) => CodeType::Code2,
    (lexer::TokenKind::INTCONST(_), _) => CodeType::Code2,
    (lexer::TokenKind::LAMBDA, _) => CodeType::Code2,
    (lexer::TokenKind::LETNONREC, _) => CodeType::Code0,
    (lexer::TokenKind::LETREC, _) => CodeType::Code1,
    (lexer::TokenKind::LPAREN, _) => CodeType::Code2,
    (lexer::TokenKind::TRUE, _) => CodeType::Code2,
    (lexer::TokenKind::VAR(_), _) => CodeType::Code2,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (opn, pos) = _parse_token_Tok_LETNONREC(tokens, pos)?;
      let (recdec, pos) = _parse_fn_nxnonrecdec(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_IN(tokens, pos)?;
      let (utast2, pos) = _parse_fn_nxlet(tokens, pos)?;

      _token_pos = pos;
      let (name, utast1) = recdec;
      let (_, opnrng) = opn;
      let (_, clsrng) = utast2;
      let rng = opnrng.merge(&clsrng);
      let main = UntypedASTMain::LetExp(name, Box::new(utast1), Box::new(utast2));
      (main, rng)
    }
    CodeType::Code1 => {
      let (opn, pos) = _parse_token_Tok_LETREC(tokens, pos)?;
      let (recdec, pos) = _parse_fn_nxnonrecdec(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_IN(tokens, pos)?;
      let (utast2, pos) = _parse_fn_nxlet(tokens, pos)?;

      _token_pos = pos;
      let (name, utast) = recdec;
      let (_, opnrng) = opn;
      let (_, clsrng) = utast2;
      let rng = opnrng.merge(&clsrng);
      let para = match utast.clone() {
        (UntypedASTMain::FunExp(para, _), _) => para,
        _ => panic!(),
      };
      let main = UntypedASTMain::LetRecExp(name, para, Box::new(utast), Box::new(utast2));
      (main, rng)
    }
    CodeType::Code2 => {
      let (utast, pos) = _parse_fn_nxif(tokens, pos)?;

      _token_pos = pos;
      utast
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_nxif(tokens: &[lexer::Token], pos: usize) -> Result<(UntypedAST, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Code1,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::FALSE, _) => CodeType::Code1,
    (lexer::TokenKind::FLOATCONST(_), _) => CodeType::Code1,
    (lexer::TokenKind::IF, _) => CodeType::Code0,
    (lexer::TokenKind::INTCONST(_), _) => CodeType::Code1,
    (lexer::TokenKind::LAMBDA, _) => CodeType::Code1,
    (lexer::TokenKind::LPAREN, _) => CodeType::Code1,
    (lexer::TokenKind::TRUE, _) => CodeType::Code1,
    (lexer::TokenKind::VAR(_), _) => CodeType::Code1,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (opn, pos) = _parse_token_Tok_IF(tokens, pos)?;
      let (utast1, pos) = _parse_fn_lor(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_THEN(tokens, pos)?;
      let (utast2, pos) = _parse_fn_lor(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_ELSE(tokens, pos)?;
      let (utast3, pos) = _parse_fn_lor(tokens, pos)?;

      _token_pos = pos;

      let (_, rngs) = opn;
      let (_, rnge) = utast3;
      let rng = rngs.merge(&rnge);
      (
        UntypedASTMain::IfThenElse(Box::new(utast1), Box::new(utast2), Box::new(utast3)),
        rng,
      )
    }
    CodeType::Code1 => {
      let (utast, pos) = _parse_fn_lor(tokens, pos)?;

      _token_pos = pos;
      utast
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_lor(tokens: &[lexer::Token], pos: usize) -> Result<(UntypedAST, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::FALSE, _) => CodeType::Code0,
    (lexer::TokenKind::FLOATCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::INTCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::LAMBDA, _) => CodeType::Code0,
    (lexer::TokenKind::LPAREN, _) => CodeType::Code0,
    (lexer::TokenKind::TRUE, _) => CodeType::Code0,
    (lexer::TokenKind::VAR(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (utast, pos) = _parse_fn_land(tokens, pos)?;
      let (utaststr2opt, pos) = _parse_fn_lor_sub(tokens, pos)?;

      _token_pos = pos;

      match utaststr2opt {
        None => utast,
        Some((op, utastr)) => {
          let (tok, rng) = op;
          let st = lexer::get_string(tok).unwrap();
          types::binary_operator(utast, (st, rng), utastr)
        }
      }
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_lor_sub(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(Option<(lexer::Token, UntypedAST)>, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::BINOP_BAR(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (op, pos) = _parse_token_Tok_BINOP_BAR(tokens, pos)?;
      let (utastr, pos) = _parse_fn_land(tokens, pos)?;
      let (subopt, pos) = _parse_fn_lor_sub(tokens, pos)?;

      _token_pos = pos;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    _ => None,
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_land(tokens: &[lexer::Token], pos: usize) -> Result<(UntypedAST, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::FALSE, _) => CodeType::Code0,
    (lexer::TokenKind::FLOATCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::INTCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::LAMBDA, _) => CodeType::Code0,
    (lexer::TokenKind::LPAREN, _) => CodeType::Code0,
    (lexer::TokenKind::TRUE, _) => CodeType::Code0,
    (lexer::TokenKind::VAR(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (utast, pos) = _parse_fn_leq_lt_gt(tokens, pos)?;
      let (utaststr2opt, pos) = _parse_fn_land_sub(tokens, pos)?;

      _token_pos = pos;

      match utaststr2opt {
        None => utast,
        Some((op, utastr)) => {
          let (tok, rng) = op;
          let st = lexer::get_string(tok).unwrap();
          types::binary_operator(utast, (st, rng), utastr)
        }
      }
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_land_sub(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(Option<(lexer::Token, UntypedAST)>, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::BINOP_AMP(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (op, pos) = _parse_token_Tok_BINOP_AMP(tokens, pos)?;
      let (utastr, pos) = _parse_fn_leq_lt_gt(tokens, pos)?;
      let (subopt, pos) = _parse_fn_land_sub(tokens, pos)?;

      _token_pos = pos;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    _ => None,
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_leq_lt_gt(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(UntypedAST, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::FALSE, _) => CodeType::Code0,
    (lexer::TokenKind::FLOATCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::INTCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::LAMBDA, _) => CodeType::Code0,
    (lexer::TokenKind::LPAREN, _) => CodeType::Code0,
    (lexer::TokenKind::TRUE, _) => CodeType::Code0,
    (lexer::TokenKind::VAR(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (utast, pos) = _parse_fn_lhat(tokens, pos)?;
      let (utaststr2opt, pos) = _parse_fn_leq_lt_gt_sub(tokens, pos)?;

      _token_pos = pos;

      match utaststr2opt {
        None => utast,
        Some((op, utastr)) => {
          let (tok, rng) = op;
          let st = lexer::get_string(tok).unwrap();
          types::binary_operator(utast, (st, rng), utastr)
        }
      }
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_leq_lt_gt_sub(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(Option<(lexer::Token, UntypedAST)>, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Code1,
    Code2,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::BINOP_EQ(_), _) => CodeType::Code0,
    (lexer::TokenKind::BINOP_GT(_), _) => CodeType::Code2,
    (lexer::TokenKind::BINOP_LT(_), _) => CodeType::Code1,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (op, pos) = _parse_token_Tok_BINOP_EQ(tokens, pos)?;
      let (utastr, pos) = _parse_fn_lhat(tokens, pos)?;
      let (subopt, pos) = _parse_fn_leq_lt_gt_sub(tokens, pos)?;

      _token_pos = pos;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    CodeType::Code1 => {
      let (op, pos) = _parse_token_Tok_BINOP_LT(tokens, pos)?;
      let (utastr, pos) = _parse_fn_lhat(tokens, pos)?;
      let (subopt, pos) = _parse_fn_leq_lt_gt_sub(tokens, pos)?;

      _token_pos = pos;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    CodeType::Code2 => {
      let (op, pos) = _parse_token_Tok_BINOP_GT(tokens, pos)?;
      let (utastr, pos) = _parse_fn_lhat(tokens, pos)?;
      let (subopt, pos) = _parse_fn_leq_lt_gt_sub(tokens, pos)?;

      _token_pos = pos;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    _ => None,
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_lhat(tokens: &[lexer::Token], pos: usize) -> Result<(UntypedAST, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::FALSE, _) => CodeType::Code0,
    (lexer::TokenKind::FLOATCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::INTCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::LAMBDA, _) => CodeType::Code0,
    (lexer::TokenKind::LPAREN, _) => CodeType::Code0,
    (lexer::TokenKind::TRUE, _) => CodeType::Code0,
    (lexer::TokenKind::VAR(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (utast, pos) = _parse_fn_lpl_mi(tokens, pos)?;
      let (utaststr2opt, pos) = _parse_fn_lhat_sub(tokens, pos)?;

      _token_pos = pos;

      match utaststr2opt {
        None => utast,
        Some((op, utastr)) => {
          let (tok, rng) = op;
          let st = lexer::get_string(tok).unwrap();
          types::binary_operator(utast, (st, rng), utastr)
        }
      }
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_lhat_sub(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(Option<(lexer::Token, UntypedAST)>, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::BINOP_HAT(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (op, pos) = _parse_token_Tok_BINOP_HAT(tokens, pos)?;
      let (utastr, pos) = _parse_fn_lpl_mi(tokens, pos)?;
      let (subopt, pos) = _parse_fn_lhat_sub(tokens, pos)?;

      _token_pos = pos;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    _ => None,
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_lpl_mi(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(UntypedAST, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::FALSE, _) => CodeType::Code0,
    (lexer::TokenKind::FLOATCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::INTCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::LAMBDA, _) => CodeType::Code0,
    (lexer::TokenKind::LPAREN, _) => CodeType::Code0,
    (lexer::TokenKind::TRUE, _) => CodeType::Code0,
    (lexer::TokenKind::VAR(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (utast, pos) = _parse_fn_lti_div(tokens, pos)?;
      let (utaststr2opt, pos) = _parse_fn_lpl_mi_sub(tokens, pos)?;

      _token_pos = pos;

      match utaststr2opt {
        None => utast,
        Some((op, utastr)) => {
          let (tok, rng) = op;
          let st = lexer::get_string(tok).unwrap();
          types::binary_operator(utast, (st, rng), utastr)
        }
      }
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_lpl_mi_sub(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(Option<(lexer::Token, UntypedAST)>, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Code1,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::BINOP_MINUS(_), _) => CodeType::Code1,
    (lexer::TokenKind::BINOP_PLUS(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (op, pos) = _parse_token_Tok_BINOP_PLUS(tokens, pos)?;
      let (utastr, pos) = _parse_fn_lti_div(tokens, pos)?;
      let (subopt, pos) = _parse_fn_lpl_mi_sub(tokens, pos)?;

      _token_pos = pos;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    CodeType::Code1 => {
      let (op, pos) = _parse_token_Tok_BINOP_MINUS(tokens, pos)?;
      let (utastr, pos) = _parse_fn_lti_div(tokens, pos)?;
      let (subopt, pos) = _parse_fn_lpl_mi_sub(tokens, pos)?;

      _token_pos = pos;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    _ => None,
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_lti_div(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(UntypedAST, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::FALSE, _) => CodeType::Code0,
    (lexer::TokenKind::FLOATCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::INTCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::LAMBDA, _) => CodeType::Code0,
    (lexer::TokenKind::LPAREN, _) => CodeType::Code0,
    (lexer::TokenKind::TRUE, _) => CodeType::Code0,
    (lexer::TokenKind::VAR(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (utast, pos) = _parse_fn_app(tokens, pos)?;
      let (utaststr2opt, pos) = _parse_fn_lti_div_sub(tokens, pos)?;

      _token_pos = pos;

      match utaststr2opt {
        None => utast,
        Some((op, utastr)) => {
          let (tok, rng) = op;
          let st = lexer::get_string(tok).unwrap();
          types::binary_operator(utast, (st, rng), utastr)
        }
      }
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_lti_div_sub(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(Option<(lexer::Token, UntypedAST)>, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Code1,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::BINOP_DIVIDES(_), _) => CodeType::Code1,
    (lexer::TokenKind::BINOP_TIMES(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (op, pos) = _parse_token_Tok_BINOP_TIMES(tokens, pos)?;
      let (utastr, pos) = _parse_fn_app(tokens, pos)?;
      let (subopt, pos) = _parse_fn_lti_div_sub(tokens, pos)?;

      _token_pos = pos;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    CodeType::Code1 => {
      let (op, pos) = _parse_token_Tok_BINOP_DIVIDES(tokens, pos)?;
      let (utastr, pos) = _parse_fn_bot(tokens, pos)?;
      let (subopt, pos) = _parse_fn_lti_div_sub(tokens, pos)?;

      _token_pos = pos;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    _ => None,
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_app(tokens: &[lexer::Token], pos: usize) -> Result<(UntypedAST, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Code1,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::FALSE, _) => CodeType::Code0,
    (lexer::TokenKind::FLOATCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::INTCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::LAMBDA, _) => CodeType::Code0,
    (lexer::TokenKind::LPAREN, _) => CodeType::Code0,
    (lexer::TokenKind::TRUE, _) => CodeType::Code0,
    (lexer::TokenKind::VAR(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (utast1, pos) = _parse_fn_bot(tokens, pos)?;
      let (utast2_lst, pos) = _parse_fn_app_sub(tokens, pos)?;

      _token_pos = pos;

      let mut v = utast2_lst;
      v.reverse();
      let mut utast = utast1;
      for utast2 in v.iter() {
        let (_, rng1) = utast;
        let (_, rng2) = utast2;
        let rng = rng1.merge(rng2);
        let new_utast = (
          UntypedASTMain::Apply(Box::new(utast), Box::new(utast2.clone())),
          rng,
        );
        utast = new_utast;
      }
      utast
    }
    CodeType::Code1 => {
      let (v, pos) = _parse_fn_bot(tokens, pos)?;

      _token_pos = pos;
      v
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_app_sub(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(Vec<UntypedAST>, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::FALSE, _) => CodeType::Code0,
    (lexer::TokenKind::FLOATCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::INTCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::LAMBDA, _) => CodeType::Code0,
    (lexer::TokenKind::LPAREN, _) => CodeType::Code0,
    (lexer::TokenKind::TRUE, _) => CodeType::Code0,
    (lexer::TokenKind::VAR(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (utast1, pos) = _parse_fn_bot(tokens, pos)?;
      let (utast2_lst, pos) = _parse_fn_app_sub(tokens, pos)?;

      _token_pos = pos;

      let mut v = utast2_lst;
      v.push(utast1);
      v
    }
    _ => Vec::new(),
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_add_sub2(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(Vec<types::UntypedAST>, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::COMMA, _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (_, pos) = _parse_token_Tok_COMMA(tokens, pos)?;
      let (lst, pos) = _parse_fn_app_sub(tokens, pos)?;

      _token_pos = pos;
      lst
    }
    _ => Vec::new(),
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_bot(tokens: &[lexer::Token], pos: usize) -> Result<(UntypedAST, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Code1,
    Code2,
    Code3,
    Code4,
    Code5,
    Code6,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::FALSE, _) => CodeType::Code3,
    (lexer::TokenKind::FLOATCONST(_), _) => CodeType::Code1,
    (lexer::TokenKind::INTCONST(_), _) => CodeType::Code0,
    (lexer::TokenKind::LAMBDA, _) => CodeType::Code6,
    (lexer::TokenKind::LPAREN, _) => CodeType::Code4,
    (lexer::TokenKind::TRUE, _) => CodeType::Code2,
    (lexer::TokenKind::VAR(_), _) => CodeType::Code5,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (inttok, pos) = _parse_token_Tok_INTCONST(tokens, pos)?;

      _token_pos = pos;

      let (tok, rng) = inttok;
      let i = lexer::get_i64(tok).unwrap();
      (UntypedASTMain::IntConst(i), rng)
    }
    CodeType::Code1 => {
      let (floattok, pos) = _parse_token_Tok_FLOATCONST(tokens, pos)?;

      _token_pos = pos;

      let (tok, rng) = floattok;
      let f = lexer::get_f64(tok).unwrap();
      (UntypedASTMain::FloatConst(f), rng)
    }
    CodeType::Code2 => {
      let (truetok, pos) = _parse_token_Tok_TRUE(tokens, pos)?;

      _token_pos = pos;

      let (_, rng) = truetok;
      (UntypedASTMain::BoolConst(true), rng)
    }
    CodeType::Code3 => {
      let (falsetok, pos) = _parse_token_Tok_FALSE(tokens, pos)?;

      _token_pos = pos;

      let (_, rng) = falsetok;
      (UntypedASTMain::BoolConst(false), rng)
    }
    CodeType::Code4 => {
      let (opn, pos) = _parse_token_Tok_LPAREN(tokens, pos)?;
      let (utast_and_rng, pos) = _parse_fn_paren_nxlet_or_binop(tokens, pos)?;

      _token_pos = pos;

      let (_, opnrng) = opn;
      let (utast, clsrng) = utast_and_rng;
      let (main, _) = utast;
      (main, opnrng.merge(&clsrng))
    }
    CodeType::Code5 => {
      let (var, pos) = _parse_token_Tok_VAR(tokens, pos)?;

      _token_pos = pos;

      let (vartok, rng) = var;
      let varnm = lexer::get_string(vartok).unwrap();
      (UntypedASTMain::ContentOf(Vec::new(), varnm), rng)
    }
    CodeType::Code6 => {
      let (opn, pos) = _parse_token_Tok_LAMBDA(tokens, pos)?;
      let (vars, pos) = _parse_fn_varlist_non_empty(tokens, pos)?;
      let (_, pos) = _parse_token_Tok_ARROW(tokens, pos)?;
      let (utast, pos) = _parse_fn_nxlet(tokens, pos)?;

      _token_pos = pos;
      let (_, opnrng) = opn;
      let (_, clsrng) = utast;
      let rng = opnrng.merge(&clsrng);
      types::make_lambda_list(vars, utast, rng)
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_paren_nxlet_or_binop(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<((UntypedAST, Range), usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Code1,
    Code2,
    Code3,
    Code4,
    Code5,
    Code6,
    Code7,
    Code8,
    Code9,
    Code10,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::BINOP_AMP(_), _) => CodeType::Code5,
    (lexer::TokenKind::BINOP_BAR(_), _) => CodeType::Code6,
    (lexer::TokenKind::BINOP_DIVIDES(_), _) => CodeType::Code1,
    (lexer::TokenKind::BINOP_EQ(_), _) => CodeType::Code9,
    (lexer::TokenKind::BINOP_GT(_), _) => CodeType::Code7,
    (lexer::TokenKind::BINOP_HAT(_), _) => CodeType::Code4,
    (lexer::TokenKind::BINOP_LT(_), _) => CodeType::Code8,
    (lexer::TokenKind::BINOP_MINUS(_), _) => CodeType::Code3,
    (lexer::TokenKind::BINOP_PLUS(_), _) => CodeType::Code2,
    (lexer::TokenKind::BINOP_TIMES(_), _) => CodeType::Code0,
    (lexer::TokenKind::FALSE, _) => CodeType::Code10,
    (lexer::TokenKind::FLOATCONST(_), _) => CodeType::Code10,
    (lexer::TokenKind::IF, _) => CodeType::Code10,
    (lexer::TokenKind::INTCONST(_), _) => CodeType::Code10,
    (lexer::TokenKind::LAMBDA, _) => CodeType::Code10,
    (lexer::TokenKind::LETNONREC, _) => CodeType::Code10,
    (lexer::TokenKind::LETREC, _) => CodeType::Code10,
    (lexer::TokenKind::LPAREN, _) => CodeType::Code10,
    (lexer::TokenKind::TRUE, _) => CodeType::Code10,
    (lexer::TokenKind::VAR(_), _) => CodeType::Code10,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (binop, pos) = _parse_token_Tok_BINOP_TIMES(tokens, pos)?;
      let (cls, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (_, clsrng) = cls;
      let (binoptok, binoprng) = binop;
      let binopstr = lexer::get_string(binoptok).unwrap();
      let utastmain = UntypedASTMain::ContentOf(Vec::new(), binopstr);
      ((utastmain, binoprng), clsrng)
    }
    CodeType::Code1 => {
      let (binop, pos) = _parse_token_Tok_BINOP_DIVIDES(tokens, pos)?;
      let (cls, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (_, clsrng) = cls;
      let (binoptok, binoprng) = binop;
      let binopstr = lexer::get_string(binoptok).unwrap();
      let utastmain = UntypedASTMain::ContentOf(Vec::new(), binopstr);
      ((utastmain, binoprng), clsrng)
    }
    CodeType::Code2 => {
      let (binop, pos) = _parse_token_Tok_BINOP_PLUS(tokens, pos)?;
      let (cls, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (_, clsrng) = cls;
      let (binoptok, binoprng) = binop;
      let binopstr = lexer::get_string(binoptok).unwrap();
      let utastmain = UntypedASTMain::ContentOf(Vec::new(), binopstr);
      ((utastmain, binoprng), clsrng)
    }
    CodeType::Code3 => {
      let (binop, pos) = _parse_token_Tok_BINOP_MINUS(tokens, pos)?;
      let (cls, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (_, clsrng) = cls;
      let (binoptok, binoprng) = binop;
      let binopstr = lexer::get_string(binoptok).unwrap();
      let utastmain = UntypedASTMain::ContentOf(Vec::new(), binopstr);
      ((utastmain, binoprng), clsrng)
    }
    CodeType::Code4 => {
      let (binop, pos) = _parse_token_Tok_BINOP_HAT(tokens, pos)?;
      let (cls, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (_, clsrng) = cls;
      let (binoptok, binoprng) = binop;
      let binopstr = lexer::get_string(binoptok).unwrap();
      let utastmain = UntypedASTMain::ContentOf(Vec::new(), binopstr);
      ((utastmain, binoprng), clsrng)
    }
    CodeType::Code5 => {
      let (binop, pos) = _parse_token_Tok_BINOP_AMP(tokens, pos)?;
      let (cls, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (_, clsrng) = cls;
      let (binoptok, binoprng) = binop;
      let binopstr = lexer::get_string(binoptok).unwrap();
      let utastmain = UntypedASTMain::ContentOf(Vec::new(), binopstr);
      ((utastmain, binoprng), clsrng)
    }
    CodeType::Code6 => {
      let (binop, pos) = _parse_token_Tok_BINOP_BAR(tokens, pos)?;
      let (cls, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (_, clsrng) = cls;
      let (binoptok, binoprng) = binop;
      let binopstr = lexer::get_string(binoptok).unwrap();
      let utastmain = UntypedASTMain::ContentOf(Vec::new(), binopstr);
      ((utastmain, binoprng), clsrng)
    }
    CodeType::Code7 => {
      let (binop, pos) = _parse_token_Tok_BINOP_GT(tokens, pos)?;
      let (cls, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (_, clsrng) = cls;
      let (binoptok, binoprng) = binop;
      let binopstr = lexer::get_string(binoptok).unwrap();
      let utastmain = UntypedASTMain::ContentOf(Vec::new(), binopstr);
      ((utastmain, binoprng), clsrng)
    }
    CodeType::Code8 => {
      let (binop, pos) = _parse_token_Tok_BINOP_LT(tokens, pos)?;
      let (cls, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (_, clsrng) = cls;
      let (binoptok, binoprng) = binop;
      let binopstr = lexer::get_string(binoptok).unwrap();
      let utastmain = UntypedASTMain::ContentOf(Vec::new(), binopstr);
      ((utastmain, binoprng), clsrng)
    }
    CodeType::Code9 => {
      let (binop, pos) = _parse_token_Tok_BINOP_EQ(tokens, pos)?;
      let (cls, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (_, clsrng) = cls;
      let (binoptok, binoprng) = binop;
      let binopstr = lexer::get_string(binoptok).unwrap();
      let utastmain = UntypedASTMain::ContentOf(Vec::new(), binopstr);
      ((utastmain, binoprng), clsrng)
    }
    CodeType::Code10 => {
      let (utast, pos) = _parse_fn_nxlet(tokens, pos)?;
      let (cls, pos) = _parse_token_Tok_RPAREN(tokens, pos)?;

      _token_pos = pos;
      let (_, clsrng) = cls;
      (utast, clsrng)
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_varlist(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(Vec<String>, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::VAR(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (var, pos) = _parse_token_Tok_VAR(tokens, pos)?;
      let (tail, pos) = _parse_fn_varlistsub(tokens, pos)?;

      _token_pos = pos;
      let mut v = tail;
      let (vartok, _) = var;
      v.push(lexer::get_string(vartok).unwrap());
      v
    }
    _ => Vec::new(),
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_varlist_non_empty(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(Vec<String>, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::VAR(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (var, pos) = _parse_token_Tok_VAR(tokens, pos)?;
      let (tail, pos) = _parse_fn_varlistsub(tokens, pos)?;

      _token_pos = pos;
      let mut v = tail;
      let (vartok, _) = var;
      v.push(lexer::get_string(vartok).unwrap());
      v
    }
    _ => {
      return Err(ParseError::UnexpectedToken(
        tokens.iter().next().unwrap().clone(),
      ))
    }
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_fn_varlistsub(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(Vec<String>, usize), ParseError> {
  let mut _token_pos = pos;
  let token1 = tokens.get(pos);
  enum CodeType {
    Code0,
    Other,
  }
  let code_type = token1.ok_or(ParseError::Eof).map(|tok| match tok {
    (lexer::TokenKind::VAR(_), _) => CodeType::Code0,

    _ => CodeType::Other,
  });
  let main = match code_type? {
    CodeType::Code0 => {
      let (var, pos) = _parse_token_Tok_VAR(tokens, pos)?;
      let (tail, pos) = _parse_fn_varlistsub(tokens, pos)?;

      _token_pos = pos;
      let mut v = tail;
      let (vartok, _) = var;
      v.push(lexer::get_string(vartok).unwrap());
      v
    }
    _ => Vec::new(),
  };
  Ok((main, _token_pos))
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_EOF(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::EOF, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_VAR(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::VAR(_), _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_CONSTRUCTOR(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::CONSTRUCTOR(_), _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_INTCONST(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::INTCONST(_), _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_FLOATCONST(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::FLOATCONST(_), _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_DEF_EQ(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::DEF_EQ, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_BINOP_TIMES(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::BINOP_TIMES(_), _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_BINOP_DIVIDES(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::BINOP_DIVIDES(_), _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_BINOP_PLUS(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::BINOP_PLUS(_), _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_BINOP_MINUS(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::BINOP_MINUS(_), _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_BINOP_HAT(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::BINOP_HAT(_), _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_BINOP_AMP(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::BINOP_AMP(_), _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_BINOP_BAR(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::BINOP_BAR(_), _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_BINOP_GT(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::BINOP_GT(_), _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_BINOP_LT(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::BINOP_LT(_), _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_BINOP_EQ(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::BINOP_EQ(_), _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_LPAREN(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::LPAREN, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_RPAREN(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::RPAREN, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_SEMICOLON(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::SEMICOLON, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_COLON(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::COLON, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_COMMA(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::COMMA, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_LETNONREC(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::LETNONREC, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_LETREC(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::LETREC, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_LETAND(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::LETAND, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_IN(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::IN, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_LAMBDA(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::LAMBDA, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_ARROW(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::ARROW, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_TRUE(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::TRUE, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_FALSE(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::FALSE, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_IF(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::IF, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_THEN(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::THEN, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
#[allow(clippy::type_complexity)]
fn _parse_token_Tok_ELSE(
  tokens: &[lexer::Token],
  pos: usize,
) -> Result<(lexer::Token, usize), ParseError> {
  let token1 = tokens.get(pos);
  token1.ok_or(ParseError::Eof).and_then(|tok| match tok {
    (lexer::TokenKind::ELSE, _) => Ok((tok.clone(), pos + 1)),
    _ => Err(ParseError::UnexpectedToken(tok.clone())),
  })
}
