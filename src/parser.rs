//
// This file was generated by llmaker.
//

use super::lexer;
use super::types;
use super::types::{UntypedAST, UntypedASTMain};
use std::iter::Peekable;

#[derive(Debug, Clone)]
pub enum ParseError {
  UnexpectedToken(lexer::Token),
  RedundantExpression(lexer::Token),
  Eof,
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
pub fn parse(tokens: Vec<lexer::Token>) -> Result<UntypedAST, ParseError> {
  let mut tokens = tokens.into_iter().peekable();
  let ret = _parse_fn_main(&mut tokens)?;
  match tokens.next() {
    Some(tok) => Err(ParseError::RedundantExpression(tok)),
    None => Ok(ret),
  }
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_main<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Tok2,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::FALSE, _)
      | (lexer::TokenKind::FLOATCONST(_), _)
      | (lexer::TokenKind::IF, _)
      | (lexer::TokenKind::INTCONST(_), _)
      | (lexer::TokenKind::LPAREN, _)
      | (lexer::TokenKind::TRUE, _)
      | (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok1),
      (lexer::TokenKind::LETNONREC, _) => Ok(CodeType::Tok2),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let utast = _parse_fn_nxif(tokens)?;
      let _ = _parse_token_Tok_EOF(tokens)?;
      utast
    }
    CodeType::Tok2 => {
      let utast = _parse_fn_nxtoplevel(tokens)?;
      utast
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_nxtoplevel<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::LETNONREC, _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let opn = _parse_token_Tok_LETNONREC(tokens)?;
      let recdec = _parse_fn_nxnonrecdec(tokens)?;
      let subseq = _parse_fn_nxtopsubseq(tokens)?;
      let (name, utast) = recdec;
      let (_, opnrng) = opn;
      let (_, clsrng) = subseq;
      let rng = opnrng.merge(&clsrng);
      let main = UntypedASTMain::LetExp(name, Box::new(utast), Box::new(subseq));
      (main, rng)
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_nxnonrecdec<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<(String, UntypedAST), ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let name = _parse_token_Tok_VAR(tokens)?;
      let _ = _parse_token_Tok_DEF_EQ(tokens)?;
      let utast = _parse_fn_nxlet(tokens)?;
      let (name_token, _) = name;
      let name_string = lexer::get_string(name_token).unwrap();
      (name_string, utast)
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_nxtopsubseq<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Tok2,
    Tok3,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::LETNONREC, _) => Ok(CodeType::Tok1),
      (lexer::TokenKind::EOF, _) => Ok(CodeType::Tok2),
      (lexer::TokenKind::IN, _) => Ok(CodeType::Tok3),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let utast = _parse_fn_nxtoplevel(tokens)?;
      utast
    }
    CodeType::Tok2 => {
      let eof = _parse_token_Tok_EOF(tokens)?;
      let (_, rng) = eof;
      (UntypedASTMain::FinishHeaderFile, rng)
    }
    CodeType::Tok3 => {
      let _ = _parse_token_Tok_IN(tokens)?;
      let utast = _parse_fn_nxlet(tokens)?;
      let _ = _parse_token_Tok_EOF(tokens)?;
      utast
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_nxlet<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Tok2,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::LETNONREC, _) => Ok(CodeType::Tok1),
      (lexer::TokenKind::FALSE, _)
      | (lexer::TokenKind::FLOATCONST(_), _)
      | (lexer::TokenKind::IF, _)
      | (lexer::TokenKind::INTCONST(_), _)
      | (lexer::TokenKind::LPAREN, _)
      | (lexer::TokenKind::TRUE, _)
      | (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok2),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let opn = _parse_token_Tok_LETNONREC(tokens)?;
      let recdec = _parse_fn_nxnonrecdec(tokens)?;
      let _ = _parse_token_Tok_IN(tokens)?;
      let utast2 = _parse_fn_nxlet(tokens)?;
      let (name, utast1) = recdec;
      let (_, opnrng) = opn;
      let (_, clsrng) = utast2;
      let rng = opnrng.merge(&clsrng);
      let main = UntypedASTMain::LetExp(name, Box::new(utast1), Box::new(utast2));
      (main, rng)
    }
    CodeType::Tok2 => {
      let utast = _parse_fn_nxif(tokens)?;
      utast
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_nxif<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Tok2,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::IF, _) => Ok(CodeType::Tok1),
      (lexer::TokenKind::FALSE, _)
      | (lexer::TokenKind::FLOATCONST(_), _)
      | (lexer::TokenKind::INTCONST(_), _)
      | (lexer::TokenKind::LPAREN, _)
      | (lexer::TokenKind::TRUE, _)
      | (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok2),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let opn = _parse_token_Tok_IF(tokens)?;
      let utast1 = _parse_fn_lor(tokens)?;
      let _ = _parse_token_Tok_THEN(tokens)?;
      let utast2 = _parse_fn_lor(tokens)?;
      let _ = _parse_token_Tok_ELSE(tokens)?;
      let utast3 = _parse_fn_lor(tokens)?;

      let (_, rngs) = opn;
      let (_, rnge) = utast3;
      let rng = rngs.merge(&rnge);
      (
        UntypedASTMain::IfThenElse(Box::new(utast1), Box::new(utast2), Box::new(utast3)),
        rng,
      )
    }
    CodeType::Tok2 => {
      let utast = _parse_fn_lor(tokens)?;
      utast
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_lor<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::FALSE, _)
      | (lexer::TokenKind::FLOATCONST(_), _)
      | (lexer::TokenKind::INTCONST(_), _)
      | (lexer::TokenKind::LPAREN, _)
      | (lexer::TokenKind::TRUE, _)
      | (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let utast = _parse_fn_land(tokens)?;
      let utaststr2opt = _parse_fn_lor_sub(tokens)?;

      match utaststr2opt {
        None => utast,
        Some((op, utastr)) => {
          let (tok, rng) = op;
          let st = lexer::get_string(tok).unwrap();
          types::binary_operator(utast, (st, rng), utastr)
        }
      }
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_lor_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Option<(lexer::Token, UntypedAST)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::BINOP_BAR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let op = _parse_token_Tok_BINOP_BAR(tokens)?;
      let utastr = _parse_fn_land(tokens)?;
      let subopt = _parse_fn_lor_sub(tokens)?;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    _ => None,
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_land<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::FALSE, _)
      | (lexer::TokenKind::FLOATCONST(_), _)
      | (lexer::TokenKind::INTCONST(_), _)
      | (lexer::TokenKind::LPAREN, _)
      | (lexer::TokenKind::TRUE, _)
      | (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let utast = _parse_fn_leq_lt_gt(tokens)?;
      let utaststr2opt = _parse_fn_land_sub(tokens)?;

      match utaststr2opt {
        None => utast,
        Some((op, utastr)) => {
          let (tok, rng) = op;
          let st = lexer::get_string(tok).unwrap();
          types::binary_operator(utast, (st, rng), utastr)
        }
      }
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_land_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Option<(lexer::Token, UntypedAST)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::BINOP_AMP(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let op = _parse_token_Tok_BINOP_AMP(tokens)?;
      let utastr = _parse_fn_leq_lt_gt(tokens)?;
      let subopt = _parse_fn_land_sub(tokens)?;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    _ => None,
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_leq_lt_gt<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::FALSE, _)
      | (lexer::TokenKind::FLOATCONST(_), _)
      | (lexer::TokenKind::INTCONST(_), _)
      | (lexer::TokenKind::LPAREN, _)
      | (lexer::TokenKind::TRUE, _)
      | (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let utast = _parse_fn_lhat(tokens)?;
      let utaststr2opt = _parse_fn_leq_lt_gt_sub(tokens)?;

      match utaststr2opt {
        None => utast,
        Some((op, utastr)) => {
          let (tok, rng) = op;
          let st = lexer::get_string(tok).unwrap();
          types::binary_operator(utast, (st, rng), utastr)
        }
      }
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_leq_lt_gt_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Option<(lexer::Token, UntypedAST)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Tok2,
    Tok3,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::BINOP_EQ(_), _) => Ok(CodeType::Tok1),
      (lexer::TokenKind::BINOP_LT(_), _) => Ok(CodeType::Tok2),
      (lexer::TokenKind::BINOP_GT(_), _) => Ok(CodeType::Tok3),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let op = _parse_token_Tok_BINOP_EQ(tokens)?;
      let utastr = _parse_fn_lhat(tokens)?;
      let subopt = _parse_fn_leq_lt_gt_sub(tokens)?;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    CodeType::Tok2 => {
      let op = _parse_token_Tok_BINOP_LT(tokens)?;
      let utastr = _parse_fn_lhat(tokens)?;
      let subopt = _parse_fn_leq_lt_gt_sub(tokens)?;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    CodeType::Tok3 => {
      let op = _parse_token_Tok_BINOP_GT(tokens)?;
      let utastr = _parse_fn_lhat(tokens)?;
      let subopt = _parse_fn_leq_lt_gt_sub(tokens)?;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    _ => None,
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_lhat<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::FALSE, _)
      | (lexer::TokenKind::FLOATCONST(_), _)
      | (lexer::TokenKind::INTCONST(_), _)
      | (lexer::TokenKind::LPAREN, _)
      | (lexer::TokenKind::TRUE, _)
      | (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let utast = _parse_fn_lpl_mi(tokens)?;
      let utaststr2opt = _parse_fn_lhat_sub(tokens)?;

      match utaststr2opt {
        None => utast,
        Some((op, utastr)) => {
          let (tok, rng) = op;
          let st = lexer::get_string(tok).unwrap();
          types::binary_operator(utast, (st, rng), utastr)
        }
      }
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_lhat_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Option<(lexer::Token, UntypedAST)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::BINOP_HAT(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let op = _parse_token_Tok_BINOP_HAT(tokens)?;
      let utastr = _parse_fn_lpl_mi(tokens)?;
      let subopt = _parse_fn_lhat_sub(tokens)?;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    _ => None,
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_lpl_mi<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::FALSE, _)
      | (lexer::TokenKind::FLOATCONST(_), _)
      | (lexer::TokenKind::INTCONST(_), _)
      | (lexer::TokenKind::LPAREN, _)
      | (lexer::TokenKind::TRUE, _)
      | (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let utast = _parse_fn_lti_div(tokens)?;
      let utaststr2opt = _parse_fn_lpl_mi_sub(tokens)?;

      match utaststr2opt {
        None => utast,
        Some((op, utastr)) => {
          let (tok, rng) = op;
          let st = lexer::get_string(tok).unwrap();
          types::binary_operator(utast, (st, rng), utastr)
        }
      }
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_lpl_mi_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Option<(lexer::Token, UntypedAST)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Tok2,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::BINOP_PLUS(_), _) => Ok(CodeType::Tok1),
      (lexer::TokenKind::BINOP_MINUS(_), _) => Ok(CodeType::Tok2),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let op = _parse_token_Tok_BINOP_PLUS(tokens)?;
      let utastr = _parse_fn_lti_div(tokens)?;
      let subopt = _parse_fn_lpl_mi_sub(tokens)?;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    CodeType::Tok2 => {
      let op = _parse_token_Tok_BINOP_MINUS(tokens)?;
      let utastr = _parse_fn_lti_div(tokens)?;
      let subopt = _parse_fn_lpl_mi_sub(tokens)?;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    _ => None,
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_lti_div<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::FALSE, _)
      | (lexer::TokenKind::FLOATCONST(_), _)
      | (lexer::TokenKind::INTCONST(_), _)
      | (lexer::TokenKind::LPAREN, _)
      | (lexer::TokenKind::TRUE, _)
      | (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let utast = _parse_fn_app(tokens)?;
      let utaststr2opt = _parse_fn_lti_div_sub(tokens)?;

      match utaststr2opt {
        None => utast,
        Some((op, utastr)) => {
          let (tok, rng) = op;
          let st = lexer::get_string(tok).unwrap();
          types::binary_operator(utast, (st, rng), utastr)
        }
      }
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_lti_div_sub<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<Option<(lexer::Token, UntypedAST)>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Tok2,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::BINOP_TIMES(_), _) => Ok(CodeType::Tok1),
      (lexer::TokenKind::BINOP_DIVIDES(_), _) => Ok(CodeType::Tok2),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let op = _parse_token_Tok_BINOP_TIMES(tokens)?;
      let utastr = _parse_fn_app(tokens)?;
      let subopt = _parse_fn_lti_div_sub(tokens)?;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    CodeType::Tok2 => {
      let op = _parse_token_Tok_BINOP_DIVIDES(tokens)?;
      let utastr = _parse_fn_bot(tokens)?;
      let subopt = _parse_fn_lti_div_sub(tokens)?;

      match subopt {
        None => Some((op, utastr)),
        Some((op2, utastr2)) => {
          let (tok, rng) = op2;
          let st = lexer::get_string(tok).unwrap();
          Some((op, types::binary_operator(utastr, (st, rng), utastr2)))
        }
      }
    }
    _ => None,
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_app<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::FALSE, _)
      | (lexer::TokenKind::FLOATCONST(_), _)
      | (lexer::TokenKind::INTCONST(_), _)
      | (lexer::TokenKind::LPAREN, _)
      | (lexer::TokenKind::TRUE, _)
      | (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let utast1 = _parse_fn_bot(tokens)?;
      let utast2_lst = _parse_fn_app_sub(tokens)?;

      let mut v = utast2_lst;
      v.reverse();
      let mut utast = utast1;
      for utast2 in v.iter() {
        let (_, rng1) = utast;
        let (_, rng2) = utast2;
        let rng = rng1.merge(&rng2);
        let new_utast = (
          UntypedASTMain::Apply(Box::new(utast), Box::new(utast2.clone())),
          rng,
        );
        utast = new_utast;
      }
      utast
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_app_sub<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<Vec<UntypedAST>, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::FALSE, _)
      | (lexer::TokenKind::FLOATCONST(_), _)
      | (lexer::TokenKind::INTCONST(_), _)
      | (lexer::TokenKind::LPAREN, _)
      | (lexer::TokenKind::TRUE, _)
      | (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok1),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let utast1 = _parse_fn_bot(tokens)?;
      let utast2_lst = _parse_fn_app_sub(tokens)?;

      let mut v = utast2_lst;
      v.push(utast1);
      v
    }
    _ => Vec::new(),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_fn_bot<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<UntypedAST, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  enum CodeType {
    Tok1,
    Tok2,
    Tok3,
    Tok4,
    Tok5,
    Tok6,
    Other,
  }
  let code_type = tokens
    .peek()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok {
      (lexer::TokenKind::INTCONST(_), _) => Ok(CodeType::Tok1),
      (lexer::TokenKind::FLOATCONST(_), _) => Ok(CodeType::Tok2),
      (lexer::TokenKind::TRUE, _) => Ok(CodeType::Tok3),
      (lexer::TokenKind::FALSE, _) => Ok(CodeType::Tok4),
      (lexer::TokenKind::LPAREN, _) => Ok(CodeType::Tok5),
      (lexer::TokenKind::VAR(_), _) => Ok(CodeType::Tok6),

      _ => Ok(CodeType::Other),
    });
  let main = match code_type? {
    CodeType::Tok1 => {
      let inttok = _parse_token_Tok_INTCONST(tokens)?;

      let (tok, rng) = inttok;
      let i = lexer::get_i64(tok).unwrap();
      (UntypedASTMain::IntConst(i), rng)
    }
    CodeType::Tok2 => {
      let floattok = _parse_token_Tok_FLOATCONST(tokens)?;

      let (tok, rng) = floattok;
      let f = lexer::get_f64(tok).unwrap();
      (UntypedASTMain::FloatConst(f), rng)
    }
    CodeType::Tok3 => {
      let truetok = _parse_token_Tok_TRUE(tokens)?;

      let (_, rng) = truetok;
      (UntypedASTMain::BoolConst(true), rng)
    }
    CodeType::Tok4 => {
      let falsetok = _parse_token_Tok_FALSE(tokens)?;

      let (_, rng) = falsetok;
      (UntypedASTMain::BoolConst(false), rng)
    }
    CodeType::Tok5 => {
      let opn = _parse_token_Tok_LPAREN(tokens)?;
      let utast = _parse_fn_nxif(tokens)?;
      let cls = _parse_token_Tok_RPAREN(tokens)?;

      let (_, rngo) = opn;
      let (_, rngc) = cls;
      let (main, _) = utast;
      (main, rngo.merge(&rngc))
    }
    CodeType::Tok6 => {
      let var = _parse_token_Tok_VAR(tokens)?;

      let (vartok, rng) = var;
      let varnm = lexer::get_string(vartok).unwrap();
      (UntypedASTMain::ContentOf(Vec::new(), varnm), rng)
    }
    _ => return Err(ParseError::UnexpectedToken(tokens.next().unwrap())),
  };
  Ok(main)
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_EOF<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::EOF, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_VAR<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::VAR(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_CONSTRUCTOR<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::CONSTRUCTOR(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_INTCONST<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::INTCONST(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_FLOATCONST<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::FLOATCONST(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_DEF_EQ<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::DEF_EQ, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_TIMES<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_TIMES(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_DIVIDES<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_DIVIDES(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_PLUS<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_PLUS(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_MINUS<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_MINUS(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_HAT<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_HAT(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_AMP<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_AMP(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_BAR<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_BAR(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_GT<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_GT(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_LT<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_LT(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_BINOP_EQ<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::BINOP_EQ(_), _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_LPAREN<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::LPAREN, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_RPAREN<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::RPAREN, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_SEMICOLON<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::SEMICOLON, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_COLON<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::COLON, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_COMMA<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::COMMA, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_LETNONREC<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::LETNONREC, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_LETAND<Tokens>(
  tokens: &mut Peekable<Tokens>,
) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::LETAND, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_IN<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::IN, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_TRUE<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::TRUE, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_FALSE<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::FALSE, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_IF<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::IF, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_THEN<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::THEN, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}

#[allow(non_camel_case_types)]
#[allow(non_snake_case)]
#[allow(unused_parens)]
fn _parse_token_Tok_ELSE<Tokens>(tokens: &mut Peekable<Tokens>) -> Result<lexer::Token, ParseError>
where
  Tokens: Iterator<Item = lexer::Token>,
{
  tokens
    .next()
    .ok_or(ParseError::Eof)
    .and_then(|tok| match tok.clone() {
      (lexer::TokenKind::ELSE, _) => Ok(tok),
      _ => Err(ParseError::UnexpectedToken(tok)),
    })
}
